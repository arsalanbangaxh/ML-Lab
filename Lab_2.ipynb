{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'D:\\8th Semester\\Machine learning\\ML Labs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "from timeseires.utils.to_split import to_split\n",
    "from timeseires.utils.multivariate_multi_step import multivariate_multi_step\n",
    "from timeseires.utils.multivariate_single_step import multivariate_single_step\n",
    "from timeseires.utils.univariate_multi_step import univariate_multi_step\n",
    "from timeseires.utils.univariate_single_step import univariate_single_step\n",
    "from timeseires.utils.CosineAnnealingLRS import CosineAnnealingLRS\n",
    "from timeseires.callbacks.EpochCheckpoint import EpochCheckpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from timeseires.callbacks.TrainingMonitor import TrainingMonitor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D,TimeDistributed\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,MaxPooling1D,Concatenate,AveragePooling1D, GlobalMaxPooling1D, Input\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "import pandas as pd\n",
    "import time, pickle\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input, Reshape, Dense, Lambda\n",
    "from tensorflow.keras.layers import Layer, Flatten, LeakyReLU, concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PC:\n",
    "    @staticmethod\n",
    "    def build(time_steps, num_features, reg=0.0005):\n",
    "        # initialize the input shape to be \"channels last\" and the\n",
    "        # channels dimension itself\n",
    "        # define the model input and first CONV module\n",
    "        inputs = Input(shape=(time_steps, num_features))\n",
    "        lstm=Bidirectional(LSTM(48,return_sequences=True))(inputs)\n",
    "        lstm=LSTM(48)(lstm)\n",
    "        lstm=Activation('tanh')(lstm)\n",
    "        lstm=Dense(24)(lstm)\n",
    "        # create the model\n",
    "        model = Model(inputs, lstm, name=\"PC\")\n",
    "        \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =  PC.build(time_steps=24, num_features=21, reg=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"PC\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"PC\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">26,880</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">27,840</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m21\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m26,880\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │          \u001b[38;5;34m27,840\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │           \u001b[38;5;34m1,176\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,896</span> (218.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,896\u001b[0m (218.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,896</span> (218.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,896\u001b[0m (218.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\\\E3-cp-{epoch:04d}-loss{val_loss:.2f}.h5'\n",
    "OUTPUT_PATH = r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2'\n",
    "#FIG_PATH = os.path.sep.join([OUTPUT_PATH,\"\\h2istory.png\"])\n",
    "#JSON_PATH = os.path.sep.join([OUTPUT_PATH,\"\\h2istory.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "start_epoch = 0\n",
    "time_steps=24\n",
    "num_features=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the callback to save only the *best* model to disk\n",
    "# based on the validation loss\n",
    "EpochCheckpoint1 = ModelCheckpoint(checkpoints,\n",
    "                             monitor=\"val_loss\",\n",
    "                             save_best_only=True, \n",
    "                             verbose=1)\n",
    "#TrainingMonitor1=TrainingMonitor(FIG_PATH, jsonPath=JSON_PATH, startAt=start_epoch)\n",
    "\n",
    "# construct the set of callbacks\n",
    "callbacks = [EpochCheckpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# if there is no specific model checkpoint supplied, then initialize\n",
    "# the network and compile the model\n",
    "if model is None:\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model = PC.build(time_steps=24, num_features=21, reg=0.005)\n",
    "    opt = Adam(1e-3)\n",
    "    model.compile(loss= 'mae', optimizer=opt, metrics=[\"mae\", \"mape\"])\n",
    "# otherwise, load the checkpoint from disk\n",
    "else:\n",
    "    print(\"[INFO] loading {}...\".format(model))\n",
    "    model = load_model(model)\n",
    "\n",
    "    # update the learning rate\n",
    "    print(\"[INFO] old learning rate: {}\".format(K.get_value(model.optimizer.lr)))\n",
    "    K.set_value(model.optimizer.lr, 1e-4)\n",
    "    print(\"[INFO] new learning rate: {}\".format(K.get_value(model.optimizer.lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.0.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((84907, 21), (24259, 21), (12130, 21))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path_dataset =r'D:\\8th Semester\\Machine learning\\ML Labs\\DATASET'\n",
    "path_tr = os.path.join(path_dataset, 'AEP_train.csv')\n",
    "df_tr = pd.read_csv(path_tr)\n",
    "train_set = df_tr.iloc[:].values\n",
    "path_v = os.path.join(path_dataset, 'AEP_validation.csv')\n",
    "df_v = pd.read_csv(path_v)\n",
    "validation_set = df_v.iloc[:].values \n",
    "path_te = os.path.join(path_dataset, 'AEP_test.csv')\n",
    "df_te = pd.read_csv(path_te)\n",
    "test_set = df_te.iloc[:].values \n",
    "\n",
    "path_scaler = os.path.join(path_dataset, 'AEP_Scaler.pkl')\n",
    "scaler         = pickle.load(open(path_scaler, 'rb'))\n",
    "\n",
    "train_set.shape, validation_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps=24\n",
    "num_features=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train_X , train_y = univariate_multi_step(train_set, time_steps, target_col=0,target_len=24)\n",
    "validation_X, validation_y = univariate_multi_step(validation_set, time_steps, target_col=0,target_len=24)\n",
    "test_X, test_y = univariate_multi_step(test_set, time_steps, target_col=0,target_len=24)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "verbose = 1 #0\n",
    "batch_size = 32\n",
    "History = model.fit(train_X,\n",
    "                        train_y,\n",
    "                        batch_size=batch_size,   \n",
    "                        epochs = epochs, \n",
    "                        validation_data = (validation_X,validation_y),\n",
    "                        callbacks=callbacks,verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step \n",
      "Mean Absolute Error (MAE): 0.26\n",
      "Median Absolute Error (MedAE): 0.24\n",
      "Mean Squared Error (MSE): 0.09\n",
      "Root Mean Squared Error (RMSE): 0.31\n",
      "Mean Absolute Percentage Error (MAPE): 680.57 %\n",
      "Median Absolute Percentage Error (MDAPE): 40.79 %\n",
      "\n",
      "y_test_unscaled.shape = (200, 1)\n",
      "y_pred.shape = (200, 24)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.metrics import MeanAbsoluteError\n",
    "from keras.saving import register_keras_serializable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Simulated 3D input data: (samples, time_steps=24, features=21)\n",
    "X = np.random.rand(1000, 24, 21)   # replace with your actual data\n",
    "y = np.random.rand(1000, 1)\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_reshaped = X.reshape(-1, X.shape[2])       # reshape for scaling\n",
    "X_scaled = scaler.fit_transform(X_reshaped)\n",
    "X_scaled = X_scaled.reshape(-1, 24, 21)       # reshape back to original\n",
    "\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# Split into train/test\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fix for loading 'mae' metric\n",
    "@register_keras_serializable(package='Custom', name='mae')\n",
    "def mae(y_true, y_pred):\n",
    "    return MeanAbsoluteError()(y_true, y_pred)\n",
    "\n",
    "# Load model with fix\n",
    "model = load_model(\n",
    "    r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E3-cp-0002-loss0.04.h5',\n",
    "    custom_objects={'mae': mae}\n",
    ")\n",
    "\n",
    "# Reshape test_X to match model input (if needed)\n",
    "test_X = test_X.reshape(-1, 24, 21)\n",
    "\n",
    "# Predict and inverse transform\n",
    "y_pred_scaled = model.predict(test_X)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = scaler.inverse_transform(test_y)\n",
    "\n",
    "# Metrics\n",
    "MAE = np.mean(np.abs(y_pred - y_test_unscaled))\n",
    "MEDAE = np.median(np.abs(y_pred - y_test_unscaled))\n",
    "MSE = np.mean(np.square(y_pred - y_test_unscaled))\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAPE = np.mean(np.abs((y_test_unscaled - y_pred) / y_test_unscaled)) * 100\n",
    "MDAPE = np.median(np.abs((y_test_unscaled - y_pred) / y_test_unscaled)) * 100\n",
    "\n",
    "# Print\n",
    "print('Mean Absolute Error (MAE):', round(MAE, 2))\n",
    "print('Median Absolute Error (MedAE):', round(MEDAE, 2))\n",
    "print('Mean Squared Error (MSE):', round(MSE, 2))\n",
    "print('Root Mean Squared Error (RMSE):', round(RMSE, 2))\n",
    "print('Mean Absolute Percentage Error (MAPE):', round(MAPE, 2), '%')\n",
    "print('Median Absolute Percentage Error (MDAPE):', round(MDAPE, 2), '%')\n",
    "print('\\ny_test_unscaled.shape =', y_test_unscaled.shape)\n",
    "print('y_pred.shape =', y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E2-cp-{epoch:04d}-loss{val_loss:.2f}.h5'\n",
    "model=r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E3-cp-0002-loss0.04.h5'\n",
    "start_epoch= 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model from: D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E3-cp-0002-loss0.04.h5\n",
      "[INFO] old learning rate: 0.001\n",
      "[INFO] new learning rate: 1e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step\n",
      "Predicted shape: (100, 24)\n",
      "Actual shape: (100, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] old learning rate: 0.0010000000474974513\n",
      "[INFO] new learning rate: 9.999999747378752e-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define mae explicitly\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "\n",
    "# Dummy placeholders for data (replace with actual data)\n",
    "# test_X and test_y should be defined properly\n",
    "# scaler should be fitted on training data and reused here\n",
    "test_X = np.random.rand(100, 24, 21)\n",
    "test_y = np.random.rand(100, 1)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(test_y)\n",
    "\n",
    "# Model checkpoint path\n",
    "checkpoints = 'best_model.h5'\n",
    "\n",
    "# Check if model path exists\n",
    "model_path = r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E3-cp-0002-loss0.04.h5'\n",
    "if os.path.exists(model_path):\n",
    "    print(\"[INFO] Loading model from:\", model_path)\n",
    "    model = load_model(model_path, custom_objects={'mae': mae})\n",
    "\n",
    "    # Update learning rate\n",
    "    print(\"[INFO] old learning rate:\", model.optimizer.learning_rate.numpy())\n",
    "    model.optimizer.learning_rate.assign(1e-4)\n",
    "    print(\"[INFO] new learning rate:\", model.optimizer.learning_rate.numpy())\n",
    "else:\n",
    "    print(\"[INFO] No model found. Define and compile your model here.\")\n",
    "    # Example placeholder model structure\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(24, 21)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    opt = Adam(1e-3)\n",
    "    model.compile(loss='mae', optimizer=opt, metrics=['mae', 'mape'])\n",
    "\n",
    "# Define callbacks\n",
    "EpochCheckpoint1 = ModelCheckpoint(checkpoints, monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "callbacks = [EpochCheckpoint1]\n",
    "\n",
    "# Train the model (dummy example; replace with real data)\n",
    "# history = model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=20, callbacks=callbacks)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scaled = model.predict(test_X)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = scaler.inverse_transform(test_y)\n",
    "\n",
    "# Print shape to confirm\n",
    "print(\"Predicted shape:\", y_pred.shape)\n",
    "print(\"Actual shape:\", y_test_unscaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - loss: 0.1020 - mae: 0.2689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 634ms/step - loss: 0.1020 - mae: 0.2689 - val_loss: 0.0854 - val_mae: 0.2408\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step\n",
      "Evaluation Metrics on Validation Data:\n",
      "MAE: 0.24\n",
      "Median AE: 0.22\n",
      "MSE: 0.08\n",
      "RMSE: 0.29\n",
      "MAPE: 378.08 %\n",
      "MDAPE: 41.94 %\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 1. Imports and Setup\n",
    "# ===============================\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.metrics import MeanAbsoluteError\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "# Enable eager execution\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Fix for the 'mae' metric during model loading\n",
    "@register_keras_serializable(package='Custom', name='mae')\n",
    "def mae(y_true, y_pred):\n",
    "    return MeanAbsoluteError()(y_true, y_pred)\n",
    "\n",
    "# ===============================\n",
    "# 2. Dummy Data Setup (Replace with your actual data)\n",
    "# ===============================\n",
    "# Assume 24 time steps and 21 features as required by model\n",
    "train_X = np.random.rand(1000, 24, 21)\n",
    "train_y = np.random.rand(1000, 1)\n",
    "validation_X = np.random.rand(200, 24, 21)\n",
    "validation_y = np.random.rand(200, 1)\n",
    "\n",
    "# Scaler (for inverse transform later)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_y)\n",
    "\n",
    "# ===============================\n",
    "# 3. Load Model\n",
    "# ===============================\n",
    "model_path = r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E3-cp-0002-loss0.04.h5'\n",
    "model = load_model(model_path, custom_objects={'mae': mae})\n",
    "\n",
    "# ===============================\n",
    "# 4. Set Learning Rate\n",
    "# ===============================\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=[mae])\n",
    "\n",
    "# ===============================\n",
    "# 5. Callbacks for Saving Checkpoints\n",
    "# ===============================\n",
    "checkpoints_path = r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E2-cp-{epoch:04d}-loss{val_loss:.2f}.h5'\n",
    "callbacks = [ModelCheckpoint(checkpoints_path, save_best_only=True, monitor='val_loss')]\n",
    "\n",
    "# ===============================\n",
    "# 6. Train Model\n",
    "# ===============================\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "\n",
    "History = model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(validation_X, validation_y),\n",
    "    callbacks=callbacks,\n",
    "    verbose=verbose\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 7. Predict and Evaluate\n",
    "# ===============================\n",
    "y_pred_scaled = model.predict(validation_X)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "y_true = scaler.inverse_transform(validation_y)\n",
    "\n",
    "# ===============================\n",
    "# 8. Metrics Calculation\n",
    "# ===============================\n",
    "MAE_val = np.mean(abs(y_pred - y_true))\n",
    "MEDAE_val = np.median(abs(y_pred - y_true))\n",
    "MSE_val = np.mean(np.square(y_pred - y_true))\n",
    "RMSE_val = np.sqrt(MSE_val)\n",
    "MAPE_val = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "MDAPE_val = np.median(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# ===============================\n",
    "# 9. Print Results\n",
    "# ===============================\n",
    "print(\"Evaluation Metrics on Validation Data:\")\n",
    "print('MAE:', round(MAE_val, 2))\n",
    "print('Median AE:', round(MEDAE_val, 2))\n",
    "print('MSE:', round(MSE_val, 2))\n",
    "print('RMSE:', round(RMSE_val, 2))\n",
    "print('MAPE:', round(MAPE_val, 2), '%')\n",
    "print('MDAPE:', round(MDAPE_val, 2), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step\n",
      "Mean Absolute Error (MAE): 0.27\n",
      "Median Absolute Error (MedAE): 0.25\n",
      "Mean Squared Error (MSE): 0.11\n",
      "Root Mean Squared Error (RMSE): 0.33\n",
      "Mean Absolute Percentage Error (MAPE): 397.29 %\n",
      "Median Absolute Percentage Error (MDAPE): 43.37 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (100, 1)\n",
      "y_pred.shape=  (100, 24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = load_model(r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E3-cp-0002-loss0.04.h5')\n",
    "model = load_model(r'D:\\8th Semester\\Machine learning\\ML Labs\\lab2\\E3-cp-0002-loss0.04.h5', custom_objects={'mae': mean_absolute_error})\n",
    "y_pred_scaled   = model.predict(test_X)\n",
    "y_pred          = scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = scaler.inverse_transform(test_y)\n",
    "# Mean Absolute Error (MAE)\n",
    "MAE = np.mean(abs(y_pred - y_test_unscaled)) \n",
    "print('Mean Absolute Error (MAE): ' + str(np.round(MAE, 2)))\n",
    "\n",
    "# Median Absolute Error (MedAE)\n",
    "MEDAE = np.median(abs(y_pred - y_test_unscaled))\n",
    "print('Median Absolute Error (MedAE): ' + str(np.round(MEDAE, 2)))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "MSE = np.square(np.subtract(y_pred, y_test_unscaled)).mean()\n",
    "print('Mean Squared Error (MSE): ' + str(np.round(MSE, 2)))\n",
    "\n",
    "# Root Mean Squarred Error (RMSE) \n",
    "RMSE = np.sqrt(np.mean(np.square(y_pred - y_test_unscaled)))\n",
    "print('Root Mean Squared Error (RMSE): ' + str(np.round(RMSE, 2)))\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print('Mean Absolute Percentage Error (MAPE): ' + str(np.round(MAPE, 2)) + ' %')\n",
    "\n",
    "# Median Absolute Percentage Error (MDAPE)\n",
    "MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print('Median Absolute Percentage Error (MDAPE): ' + str(np.round(MDAPE, 2)) + ' %')\n",
    "\n",
    "print('\\n\\ny_test_unscaled.shape= ',y_test_unscaled.shape)\n",
    "print('y_pred.shape= ',y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
